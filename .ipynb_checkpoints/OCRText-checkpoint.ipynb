{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9913842-b112-4550-a80b-d4e73ece6be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "don't know how to restore data location of torch.storage.UntypedStorage (tagged with true)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m video\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m480\u001b[39m)  \u001b[38;5;66;03m# Set video height\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize EasyOCR reader for Hindi and English\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m], gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\easyocr\\easyocr.py:214\u001b[0m, in \u001b[0;36mReader.__init__\u001b[1;34m(self, lang_list, gpu, model_storage_directory, user_network_directory, detect_network, recog_network, download_enabled, detector, recognizer, verbose, quantize, cudnn_benchmark)\u001b[0m\n\u001b[0;32m    211\u001b[0m     dict_list[lang] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict\u001b[39m\u001b[38;5;124m'\u001b[39m, lang \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitDetector(detector_path)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recog_network \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\easyocr\\easyocr.py:271\u001b[0m, in \u001b[0;36mReader.initDetector\u001b[1;34m(self, detector_path)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitDetector\u001b[39m(\u001b[38;5;28mself\u001b[39m, detector_path):\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_detector(detector_path, \n\u001b[0;32m    272\u001b[0m                              device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \n\u001b[0;32m    273\u001b[0m                              quantize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantize, \n\u001b[0;32m    274\u001b[0m                              cudnn_benchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcudnn_benchmark\n\u001b[0;32m    275\u001b[0m                              )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\easyocr\\detection.py:85\u001b[0m, in \u001b[0;36mget_detector\u001b[1;34m(trained_model, device, quantize, cudnn_benchmark)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     net\u001b[38;5;241m.\u001b[39mload_state_dict(copyStateDict(torch\u001b[38;5;241m.\u001b[39mload(trained_model, map_location\u001b[38;5;241m=\u001b[39mdevice, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)))\n\u001b[0;32m     86\u001b[0m     net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(net)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     87\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m cudnn_benchmark\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1114\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1113\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[0;32m   1115\u001b[0m     opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args\n\u001b[0;32m   1116\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1348\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1347\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1348\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m   1350\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mactive_fake_mode() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1281\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     obj \u001b[38;5;241m=\u001b[39m cast(Storage, torch\u001b[38;5;241m.\u001b[39mUntypedStorage(nbytes))\n\u001b[0;32m   1280\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m     obj \u001b[38;5;241m=\u001b[39m restore_location(obj, location)\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m   1285\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1286\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1287\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1389\u001b[0m, in \u001b[0;36m_get_restore_location.<locals>.restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_location\u001b[39m(storage, location):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_restore_location(storage, map_location)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:417\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know how to restore data location of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m                    \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtypename(storage) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (tagged with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m                    \u001b[38;5;241m+\u001b[39m location \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: don't know how to restore data location of torch.storage.UntypedStorage (tagged with true)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "# Initialize video capture\n",
    "video = cv2.VideoCapture(0)\n",
    "video.set(3, 640)  # Set video width\n",
    "video.set(4, 480)  # Set video height\n",
    "\n",
    "# Initialize EasyOCR reader for Hindi and English\n",
    "reader = easyocr.Reader(['hi', 'en'], gpu=true)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    # feed = cv2.flip(frame, 1)  # Flip the frame horizontally for a mirror effect\n",
    "\n",
    "    if ret:\n",
    "        # Perform OCR on the frame\n",
    "        result = reader.readtext(frame)\n",
    "        \n",
    "        # Loop through detected text\n",
    "        for detection in result:\n",
    "            # Bounding box coordinates\n",
    "            top_left = tuple([int(val) for val in detection[0][0]])\n",
    "            bottom_right = tuple([int(val) for val in detection[0][2]])\n",
    "            \n",
    "            # Draw rectangle around detected text\n",
    "            cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "            \n",
    "            # Display the detected text above the rectangle\n",
    "            text = detection[1]\n",
    "            cv2.putText(frame, text, (top_left[0], top_left[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the video feed with rectangles and text\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d88c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
